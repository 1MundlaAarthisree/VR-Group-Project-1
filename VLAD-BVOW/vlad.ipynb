{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_train[0].shape)\n",
    "# print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import itertools\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import BallTree\n",
    "import pickle\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desSIFT(image):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(image,None)\n",
    "    #draw keypoints\n",
    "    #import matplotlib.pyplot as plt\t\t\n",
    "    #img2 = cv2.drawKeypoints(img,kp,None,(255,0,0),4)\n",
    "    #plt.imshow(img2),plt.show()\n",
    "    return kp,des\n",
    "\n",
    "def describeORB( image):\n",
    "    #An efficient alternative to SIFT or SURF\n",
    "    #doc http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_orb/py_orb.html\n",
    "    #ORB is basically a fusion of FAST keypoint detector and BRIEF descriptor \n",
    "    #with many modifications to enhance the performance\n",
    "    orb=cv2.ORB_create()\n",
    "    kp, des=orb.detectAndCompute(image,None)\n",
    "    return kp,des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDescriptors(images) : \n",
    "    descriptors = []\n",
    "    \n",
    "    for image in images : \n",
    "        print (image.shape)\n",
    "        kp, des = desSIFT(image)\n",
    "        if des is not None : \n",
    "            descriptors.append(des)\n",
    "            \n",
    "    descriptors = list(itertools.chain.from_iterable(descriptors))\n",
    "    descriptors = np.asarray(descriptors)\n",
    "        \n",
    "    return descriptors\n",
    "\n",
    "def getVLADDescriptors(images, images_lables, visualDic):\n",
    "    descriptors = []\n",
    "    labels = []\n",
    "    \n",
    "    count = 0\n",
    "    for image in images : \n",
    "        kp, des = desSIFT(image)\n",
    "        if des is not None : \n",
    "            v = VLAD(des, visualDic)\n",
    "            descriptors.append(v)\n",
    "            labels.append(images_lables[count])\n",
    "        count += 1\n",
    "            \n",
    "            \n",
    "    descriptors = list(itertools.chain.from_iterable(descriptors))\n",
    "    descriptors = np.asarray(descriptors)\n",
    "        \n",
    "    return descriptors, labels\n",
    "    \n",
    "def kMeans(training, k) : \n",
    "    est = KMeans(n_clusters = k, init = 'k-means++').fit(training)\n",
    "    return est\n",
    "\n",
    "def VLAD(X, visualDictionary) : \n",
    "    \n",
    "    predictedLabels = visualDictionary.predict(X)\n",
    "    centers = visualDictionary.cluster_centers_\n",
    "    labels = visualDictionary.labels_\n",
    "    k = visualDictionary.n_clusters\n",
    "    \n",
    "    m,d = X.shape\n",
    "    V=np.zeros([k,d])\n",
    "    #computing the differences\n",
    "\n",
    "    # for all the clusters (visual words)\n",
    "    for i in range(k):\n",
    "        # if there is at least one descriptor in that cluster\n",
    "        if np.sum(predictedLabels==i)>0:\n",
    "            # add the diferences\n",
    "            V[i]=np.sum(X[predictedLabels==i,:]-centers[i],axis=0)\n",
    "    \n",
    "\n",
    "    V = V.flatten()\n",
    "    # power normalization, also called square-rooting normalization\n",
    "    V = np.sign(V)*np.sqrt(np.abs(V))\n",
    "\n",
    "    # L2 normalization\n",
    "\n",
    "    V = V/np.sqrt(np.dot(V,V))\n",
    "    return V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_des = getDescriptors(np.concatenate((x_train, x_test), axis = 0))\n",
    "visDic = kMeans(sift_des, 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlad_des, labels = getVLADDescriptors(x_train, y_train, visDic)\n",
    "print (\"Hola\")\n",
    "vlad_des_test, labels_test = getVLADDescriptors(x_test, y_test, visDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = cv2.ml.KNearest_create()\n",
    "clf.train(vlad_des, cv2.ml.ROW_SAMPLE, np.asarray(labels, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, results, neighbours ,dist = clf.findNearest(vlad_des_test, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (results)\n",
    "print (labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
