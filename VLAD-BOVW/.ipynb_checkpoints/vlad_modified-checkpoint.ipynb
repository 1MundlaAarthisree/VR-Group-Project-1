{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0].shape)\n",
    "# print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import itertools\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.neighbors import BallTree\n",
    "import pickle\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desSURF(image):\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    kp, des = surf.detectAndCompute(image,None)\n",
    "    #draw keypoints\n",
    "    #import matplotlib.pyplot as plt\t\t\n",
    "    #img2 = cv2.drawKeypoints(img,kp,None,(255,0,0),4)\n",
    "    #plt.imshow(img2),plt.show()\n",
    "    return kp,des\n",
    "\n",
    "def describeORB( image):\n",
    "    #An efficient alternative to SIFT or SURF\n",
    "    #doc http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_orb/py_orb.html\n",
    "    #ORB is basically a fusion of FAST keypoint detector and BRIEF descriptor \n",
    "    #with many modifications to enhance the performance\n",
    "    orb=cv2.ORB_create()\n",
    "    kp, des=orb.detectAndCompute(image,None)\n",
    "    return kp,des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDescriptors(images) : \n",
    "    descriptors = []\n",
    "    \n",
    "    for image in images: \n",
    "        image = cv2.resize(image, (150, 150), interpolation=cv2.INTER_AREA)\n",
    "        kp, des = desSURF(image)\n",
    "        if des is not None : \n",
    "            descriptors.append(des)\n",
    "            \n",
    "#     descriptors = list(itertools.chain.from_iterable(descriptors))\n",
    "    descriptors = np.concatenate(descriptors, axis=0)\n",
    "#     descriptors = np.asarray(descriptors)\n",
    "    print(descriptors)\n",
    "    return descriptors\n",
    "\n",
    "# def getVLADDescriptors(images, images_lables, visualDic):\n",
    "#     descriptors = []\n",
    "#     labels = []\n",
    "    \n",
    "#     count = 0\n",
    "#     for image in images : \n",
    "#         image = cv2.resize(image, (150, 150), interpolation=cv2.INTER_AREA)\n",
    "#         kp, des = desSURF(image)\n",
    "#         if des is not None : \n",
    "#             v = VLAD(des, visualDic)\n",
    "#             descriptors.append(v)\n",
    "#             labels.append(images_lables[count])\n",
    "#         count += 1\n",
    "            \n",
    "            \n",
    "# #     descriptors = list(itertools.chain.from_iterable(descriptors))\n",
    "#     descriptors = np.concatenate(descriptors, axis=0)\n",
    "# #     descriptors = np.asarray(descriptors)\n",
    "#     print(descriptors)  \n",
    "#     return descriptors, labels\n",
    "\n",
    "def getVLADDescriptors(images, images_lables, visualDic):\n",
    "    descriptors = []\n",
    "    labels = []\n",
    "    \n",
    "    count = 0\n",
    "    for image in images : \n",
    "        kp, des = desSIFT(image)\n",
    "        if des is not None : \n",
    "            v = VLAD(des, visualDic)\n",
    "            descriptors.append(v)\n",
    "            labels.append([images_lables[count]])\n",
    "        count += 1\n",
    "            \n",
    "            \n",
    "    descriptors = list(itertools.chain.from_iterable(descriptors))\n",
    "    descriptors = np.asarray(descriptors)\n",
    "    \n",
    "    labels = np.array(labels).astype(np.float32)\n",
    "        \n",
    "    return descriptors, labels\n",
    "    \n",
    "def kMeans(training, k) : \n",
    "    est = KMeans(n_clusters = k, init = 'k-means++').fit(training)\n",
    "    return est\n",
    "\n",
    "def VLAD(X, visualDictionary) : \n",
    "    \n",
    "    predictedLabels = visualDictionary.predict(X)\n",
    "    centers = visualDictionary.cluster_centers_\n",
    "    labels = visualDictionary.labels_\n",
    "    k = visualDictionary.n_clusters\n",
    "    \n",
    "    m,d = X.shape\n",
    "    V=np.zeros([k,d])\n",
    "    #computing the differences\n",
    "\n",
    "    # for all the clusters (visual words)\n",
    "    for i in range(k):\n",
    "        # if there is at least one descriptor in that cluster\n",
    "        if np.sum(predictedLabels==i)>0:\n",
    "            # add the diferences\n",
    "            V[i]=np.sum(X[predictedLabels==i,:]-centers[i],axis=0)\n",
    "    \n",
    "\n",
    "    V = V.flatten()\n",
    "    # power normalization, also called square-rooting normalization\n",
    "    V = np.sign(V)*np.sqrt(np.abs(V))\n",
    "\n",
    "    # L2 normalization\n",
    "\n",
    "    V = V/np.sqrt(np.dot(V,V))\n",
    "    return V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00109814 -0.00018986  0.00148726 ... -0.00039803  0.00389354\n",
      "   0.00152968]\n",
      " [-0.00258623 -0.00100103  0.00301079 ...  0.00070776  0.00191917\n",
      "   0.00119535]\n",
      " [-0.00193051 -0.0003467   0.00200452 ... -0.00018438  0.00339893\n",
      "   0.00250239]\n",
      " ...\n",
      " [ 0.02049138  0.01756086  0.02092241 ... -0.02243001  0.01018546\n",
      "   0.02806576]\n",
      " [-0.0063772   0.00170187  0.00690927 ... -0.00311643  0.00075985\n",
      "   0.00416109]\n",
      " [-0.00071191  0.00137888  0.00447666 ...  0.00259698  0.00891337\n",
      "   0.00394264]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sift_keypoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c0ea3ed56206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# visDic = kMeans(sift_des, 50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m visDic = MiniBatchKMeans(init='k-means++', n_clusters=50,max_iter=1000, batch_size=1000,\n\u001b[0;32m----> 4\u001b[0;31m                   n_init=10, max_no_improvement=10, verbose=0).fit(sift_keypoints)\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sift_keypoints' is not defined"
     ]
    }
   ],
   "source": [
    "sift_des = getDescriptors(np.concatenate((x_train, x_test), axis = 0))\n",
    "# visDic = kMeans(sift_des, 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "visDic = MiniBatchKMeans(init='k-means++', n_clusters=50,max_iter=1000, batch_size=1000,\n",
    "                  n_init=10, max_no_improvement=10, verbose=0).fit(sift_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00497536 -0.00614418 -0.00048086 ... -0.002571   -0.00527096\n",
      " -0.00604971]\n",
      "Hola\n",
      "[-0.01047412 -0.01037078 -0.00143245 ... -0.00338243  0.00639427\n",
      "  0.00276779]\n"
     ]
    }
   ],
   "source": [
    "vlad_des, labels = getVLADDescriptors(x_train, y_train, visDic)\n",
    "print (\"Hola\")\n",
    "vlad_des_test, labels_test = getVLADDescriptors(x_test, y_test, visDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /io/opencv/modules/ml/src/data.cpp:298: error: (-215:Assertion failed) (layout == ROW_SAMPLE && responses.rows == nsamples) || (layout == COL_SAMPLE && responses.cols == nsamples) in function 'setData'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-9939f6f64093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# print(labels_new)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvlad_des\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROW_SAMPLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /io/opencv/modules/ml/src/data.cpp:298: error: (-215:Assertion failed) (layout == ROW_SAMPLE && responses.rows == nsamples) || (layout == COL_SAMPLE && responses.cols == nsamples) in function 'setData'\n"
     ]
    }
   ],
   "source": [
    "# clf = cv2.ml.KNearest_create()\n",
    "# # print(len(vlad_des))\n",
    "# # print(len(labels))\n",
    "# # print(labels)\n",
    "# # labels_new = []\n",
    "# # for label_array in labels : \n",
    "# #     for label in label_array:\n",
    "# #         labels_new.append(label)\n",
    "# # print(labels_new)\n",
    "# clf.train(np.float32(vlad_des), cv2.ml.ROW_SAMPLE, np.float32(labels))\n",
    "\n",
    "clf = cv2.ml.KNearest_create()\n",
    "clf.train(vlad_des, cv2.ml.ROW_SAMPLE, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /io/opencv/modules/ml/src/knearest.cpp:312: error: (-215:Assertion failed) test_samples.type() == 5 && test_samples.cols == samples.cols in function 'findNearest'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-36a84924a82d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbours\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindNearest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvlad_des_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /io/opencv/modules/ml/src/knearest.cpp:312: error: (-215:Assertion failed) test_samples.type() == 5 && test_samples.cols == samples.cols in function 'findNearest'\n"
     ]
    }
   ],
   "source": [
    "ret, results, neighbours ,dist = clf.findNearest(vlad_des_test, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (results)\n",
    "print (labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
